"""
Application Streamlit pour le projet NLP de pr√©diction de solutions techniques (PCA)
Interface utilisateur pour les ing√©nieurs non techniques
Auteur: Assistant IA
Date: 2025-07-26
"""

import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from datetime import datetime
import os
import json
from typing import Dict, List

from predict import PCAPredictor
from main import PCAMLPipeline
from gim_chatbot import GIMChatbot, demo_mode_response


# Configuration de la page
st.set_page_config(
    page_title="Pr√©dicteur PCA & Assistant GIM",
    page_icon="üîß",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS personnalis√©
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    .prediction-box {
        background-color: #f0f8ff;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #1f77b4;
        margin: 1rem 0;
    }
    .confidence-high {
        color: #28a745;
        font-weight: bold;
    }
    .confidence-medium {
        color: #ffc107;
        font-weight: bold;
    }
    .confidence-low {
        color: #dc3545;
        font-weight: bold;
    }
    .metric-card {
        background-color: #ffffff;
        padding: 1rem;
        border-radius: 8px;
        box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        text-align: center;
    }
    .gim-chat-box {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 10px;
        border-left: 5px solid #28a745;
        margin: 1rem 0;
    }
    .chat-message-user {
        background-color: #e3f2fd;
        padding: 0.5rem;
        border-radius: 8px;
        margin: 0.5rem 0;
        text-align: right;
    }
    .chat-message-bot {
        background-color: #f1f8e9;
        padding: 0.5rem;
        border-radius: 8px;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)


class PCAStreamlitApp:
    """
    Application Streamlit pour la pr√©diction de PCA avec chatbot GIM int√©gr√©
    """

    def __init__(self):
        """Initialise l'application"""
        self.predictor = None
        self.pipeline = PCAMLPipeline()
        self.gim_chatbot = GIMChatbot()

        # Configuration par d√©faut
        self.backend = "randomforest"  # Par d√©faut
        self.hf_repo = None

        # Initialisation du state
        if 'prediction_history' not in st.session_state:
            st.session_state.prediction_history = []

        if 'model_loaded' not in st.session_state:
            st.session_state.model_loaded = False

        if 'show_gim_chat' not in st.session_state:
            st.session_state.show_gim_chat = False

        if 'quick_gim_question' not in st.session_state:
            st.session_state.quick_gim_question = None
    
    def load_model(self, backend: str = None, hf_repo: str = None) -> bool:
        """
        Charge le mod√®le de pr√©diction

        Args:
            backend (str): Type de mod√®le ('randomforest' ou 'distilbert')
            hf_repo (str): Repository Hugging Face pour DistilBERT (optionnel)

        Returns:
            bool: True si le mod√®le est charg√© avec succ√®s
        """
        if backend:
            self.backend = backend
        if hf_repo:
            self.hf_repo = hf_repo

        try:
            cache_key = f"{self.backend}_{self.hf_repo or 'local'}"
            if not st.session_state.get(f"model_loaded_{cache_key}", False):
                with st.spinner(f"Chargement du mod√®le {self.backend.upper()}..."):
                    self.predictor = PCAPredictor(
                        backend=self.backend,
                        checkpoint_dir="distilbert_pca_model",
                        hf_repo=self.hf_repo
                    )
                    self.predictor.load_model()
                    st.session_state[f"model_loaded_{cache_key}"] = True
                st.success(f"‚úÖ Mod√®le {self.backend.upper()} charg√© avec succ√®s!")
            else:
                self.predictor = PCAPredictor(
                    backend=self.backend,
                    checkpoint_dir="distilbert_pca_model",
                    hf_repo=self.hf_repo
                )
                self.predictor.load_model()
            return True
        except Exception as e:
            # Fallback vers RandomForest si DistilBERT √©choue
            if self.backend == "distilbert":
                st.warning("‚ö†Ô∏è Mod√®le DistilBERT non disponible, utilisation du mod√®le RandomForest")
                return self.load_model("randomforest")
            else:
                st.error(f"‚ùå Erreur lors du chargement du mod√®le: {e}")
                st.info("üí° Assurez-vous d'avoir entra√Æn√© le mod√®le avec `python main.py --action train`")
                return False
    
    def render_header(self):
        """Affiche l'en-t√™te de l'application"""
        st.markdown('<h1 class="main-header">üîß Pr√©dicteur PCA & Assistant GIM</h1>',
                   unsafe_allow_html=True)

        st.markdown("""
        <div style="text-align: center; margin-bottom: 2rem;">
            <p style="font-size: 1.2rem; color: #666;">
                Syst√®me IA pour pr√©dire automatiquement les solutions techniques (PCA)
                √† partir de codes DTC et descriptions de pannes
            </p>
            <p style="font-size: 1rem; color: #888;">
                ü§ñ <strong>Nouveau :</strong> Assistant GIM int√©gr√© pour vos questions sur la plateforme Global Issue Management
            </p>
        </div>
        """, unsafe_allow_html=True)
    
    def render_sidebar(self):
        """Affiche la barre lat√©rale avec les informations du mod√®le"""
        st.sidebar.header("ü§ñ Configuration du Mod√®le")

        # Choix du backend
        backend_options = {
            "randomforest": "üå≤ RandomForest (Rapide)",
            "distilbert": "üß† DistilBERT (Pr√©cis)"
        }

        selected_backend = st.sidebar.selectbox(
            "Type de mod√®le",
            options=list(backend_options.keys()),
            format_func=lambda x: backend_options[x],
            index=0 if self.backend == "randomforest" else 1,
            help="RandomForest: Plus rapide, fonctionne hors ligne\nDistilBERT: Plus pr√©cis, n√©cessite plus de ressources"
        )

        # Configuration DistilBERT
        hf_repo = None
        if selected_backend == "distilbert":
            st.sidebar.subheader("‚öôÔ∏è Configuration DistilBERT")
            use_hf = st.sidebar.checkbox(
                "Utiliser Hugging Face Hub",
                help="T√©l√©charge le mod√®le depuis Hugging Face si le mod√®le local n'est pas disponible"
            )

            if use_hf:
                hf_repo = st.sidebar.text_input(
                    "Repository HF (optionnel)",
                    placeholder="ex: votre-username/pca-distilbert",
                    help="Laissez vide pour utiliser le mod√®le par d√©faut"
                )

        # Bouton pour charger/recharger le mod√®le
        if st.sidebar.button("üîÑ Charger le mod√®le", use_container_width=True):
            self.load_model(selected_backend, hf_repo)

        # Mise √† jour automatique si le backend change
        if selected_backend != self.backend:
            self.backend = selected_backend
            self.hf_repo = hf_repo

        st.sidebar.markdown("---")
        st.sidebar.header("üìä Informations du Mod√®le")

        # Informations sur le mod√®le
        model_info = self.pipeline.get_model_info()
        
        if model_info['is_trained']:
            st.sidebar.success("‚úÖ Mod√®le disponible")
            
            # Affichage des d√©tails
            st.sidebar.subheader("üìÅ Fichiers du mod√®le")
            for file, status in model_info['model_files'].items():
                if status['exists']:
                    st.sidebar.text(f"‚úÖ {file}")
                    if status['modified']:
                        modified_date = datetime.fromisoformat(status['modified']).strftime("%d/%m/%Y %H:%M")
                        st.sidebar.caption(f"   Modifi√©: {modified_date}")
                else:
                    st.sidebar.text(f"‚ùå {file}")
        else:
            st.sidebar.error("‚ùå Mod√®le non disponible")
            st.sidebar.info("Entra√Ænez d'abord le mod√®le avec la commande:\n`python main.py --action train`")
        
        # Historique des pr√©dictions
        st.sidebar.subheader("üìà Historique")
        if st.session_state.prediction_history:
            st.sidebar.text(f"Pr√©dictions effectu√©es: {len(st.session_state.prediction_history)}")

            if st.sidebar.button("üóëÔ∏è Effacer l'historique"):
                st.session_state.prediction_history = []
                st.rerun()
        else:
            st.sidebar.text("Aucune pr√©diction encore")

        # Widget chatbot GIM dans la sidebar
        self.gim_chatbot.render_sidebar_widget()
    
    def render_prediction_form(self):
        """Affiche le formulaire de pr√©diction"""
        st.header("üéØ Nouvelle Pr√©diction")
        
        with st.form("prediction_form"):
            col1, col2 = st.columns(2)
            
            with col1:
                code_dtc = st.text_input(
                    "Code DTC",
                    placeholder="Ex: P0300, P0171, B1234...",
                    help="Code de diagnostic de panne (Diagnostic Trouble Code)"
                )
                
                description = st.text_area(
                    "Description du probl√®me",
                    placeholder="Ex: Engine misfiring randomly, Check engine light on...",
                    height=100,
                    help="Description d√©taill√©e du probl√®me observ√©"
                )
            
            with col2:
                root_cause = st.text_area(
                    "Cause racine (optionnel)",
                    placeholder="Ex: Faulty spark plugs, Vacuum leak...",
                    height=100,
                    help="Description de la cause racine si connue"
                )
                
                # Options avanc√©es
                st.subheader("‚öôÔ∏è Options")
                show_probabilities = st.checkbox("Afficher toutes les probabilit√©s", value=True)
                top_n = st.slider("Nombre de pr√©dictions alternatives", 1, 5, 3)
            
            # Bouton de pr√©diction
            predict_button = st.form_submit_button("üîÆ Pr√©dire la PCA", use_container_width=True)
            
            if predict_button:
                if not code_dtc.strip() or not description.strip():
                    st.error("‚ùå Veuillez remplir au minimum le Code DTC et la Description du probl√®me")
                else:
                    self.make_prediction(code_dtc, description, root_cause, show_probabilities, top_n)
    
    def make_prediction(self, code_dtc: str, description: str, root_cause: str, 
                       show_probabilities: bool, top_n: int):
        """
        Effectue une pr√©diction et affiche les r√©sultats
        
        Args:
            code_dtc (str): Code DTC
            description (str): Description du probl√®me
            root_cause (str): Cause racine
            show_probabilities (bool): Afficher les probabilit√©s
            top_n (int): Nombre de pr√©dictions alternatives
        """
        if not self.load_model():
            return
        
        with st.spinner("Analyse en cours..."):
            try:
                # Pr√©diction principale
                result = self.predictor.predict_single(
                    code_dtc, description, root_cause, 
                    return_probabilities=show_probabilities
                )
                
                if 'error' in result:
                    st.error(f"‚ùå Erreur lors de la pr√©diction: {result['error']}")
                    return
                
                # Affichage du r√©sultat principal
                self.display_main_prediction(result)
                
                # Pr√©dictions alternatives
                if show_probabilities and top_n > 1:
                    top_predictions = self.predictor.get_top_predictions(
                        code_dtc, description, root_cause, top_n
                    )
                    self.display_alternative_predictions(top_predictions)
                
                # Explication d√©taill√©e
                explanation = self.predictor.explain_prediction(code_dtc, description, root_cause)
                self.display_explanation(explanation)
                
                # Sauvegarde dans l'historique
                self.save_to_history(result, code_dtc, description, root_cause)
                
            except Exception as e:
                st.error(f"‚ùå Erreur inattendue: {e}")
    
    def display_main_prediction(self, result: Dict):
        """Affiche le r√©sultat principal de la pr√©diction"""
        st.header("üéØ R√©sultat de la Pr√©diction")
        
        # D√©termination de la couleur selon la confiance
        confidence = result.get('confidence', 0)
        if confidence >= 0.7:
            confidence_class = "confidence-high"
            confidence_icon = "üü¢"
        elif confidence >= 0.4:
            confidence_class = "confidence-medium"
            confidence_icon = "üü°"
        else:
            confidence_class = "confidence-low"
            confidence_icon = "üî¥"
        
        # Affichage dans une bo√Æte styl√©e
        st.markdown(f"""
        <div class="prediction-box">
            <h3>üîß PCA Recommand√©e</h3>
            <h2 style="color: #1f77b4; margin: 1rem 0;">{result['predicted_pca']}</h2>
            <p><strong>Niveau de confiance:</strong> 
               <span class="{confidence_class}">{confidence_icon} {confidence:.1%}</span>
            </p>
        </div>
        """, unsafe_allow_html=True)
        
        # M√©triques en colonnes
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("Confiance", f"{confidence:.1%}")
        
        with col2:
            confidence_level = self.get_confidence_level(confidence)
            st.metric("Niveau", confidence_level)
        
        with col3:
            st.metric("Texte trait√©", f"{len(result['processed_text'].split())} mots")
    
    def display_alternative_predictions(self, top_predictions: List[Dict]):
        """Affiche les pr√©dictions alternatives"""
        st.header("üîÑ Solutions Alternatives")
        
        # Cr√©ation d'un graphique en barres
        if len(top_predictions) > 1:
            df_alternatives = pd.DataFrame([
                {
                    'PCA': pred['pca'][:50] + '...' if len(pred['pca']) > 50 else pred['pca'],
                    'Probabilit√©': pred['probability'],
                    'Confiance': pred['confidence_level']
                }
                for pred in top_predictions[1:]  # Exclure la premi√®re (d√©j√† affich√©e)
            ])
            
            fig = px.bar(
                df_alternatives, 
                x='Probabilit√©', 
                y='PCA',
                orientation='h',
                title="Probabilit√©s des Solutions Alternatives",
                color='Probabilit√©',
                color_continuous_scale='Blues'
            )
            fig.update_layout(height=300)
            st.plotly_chart(fig, use_container_width=True)
        
        # Tableau d√©taill√©
        for i, pred in enumerate(top_predictions[1:], 2):
            with st.expander(f"#{i} - {pred['pca'][:60]}... (Prob: {pred['probability']:.1%})"):
                st.write(f"**PCA compl√®te:** {pred['pca']}")
                st.write(f"**Probabilit√©:** {pred['probability']:.3f}")
                st.write(f"**Niveau de confiance:** {pred['confidence_level']}")
    
    def display_explanation(self, explanation: Dict):
        """Affiche l'explication d√©taill√©e de la pr√©diction"""
        with st.expander("üîç Explication D√©taill√©e", expanded=False):
            
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("üìù Analyse de l'entr√©e")
                st.write(f"**Texte original:**")
                st.code(f"DTC: {explanation['input_analysis']['original_input']['code_dtc']}")
                st.code(f"Description: {explanation['input_analysis']['original_input']['description']}")
                if explanation['input_analysis']['original_input']['root_cause']:
                    st.code(f"Cause: {explanation['input_analysis']['original_input']['root_cause']}")
                
                st.write(f"**Texte pr√©process√©:**")
                st.code(explanation['input_analysis']['processed_text'])
                
                st.write(f"**Statistiques:**")
                st.write(f"- Longueur: {explanation['input_analysis']['text_length']} caract√®res")
                st.write(f"- Mots: {explanation['input_analysis']['word_count']} mots")
            
            with col2:
                st.subheader("üéØ R√©sum√© de la pr√©diction")
                summary = explanation['prediction_summary']
                st.write(f"**PCA pr√©dite:** {summary['predicted_pca']}")
                st.write(f"**Confiance:** {summary['confidence']:.3f}")
                st.write(f"**Niveau:** {summary['confidence_level']}")
                
                if explanation['alternative_solutions']:
                    st.write("**Autres solutions possibles:**")
                    for alt in explanation['alternative_solutions']:
                        st.write(f"- {alt['pca'][:40]}... ({alt['probability']:.1%})")
    
    def save_to_history(self, result: Dict, code_dtc: str, description: str, root_cause: str):
        """Sauvegarde la pr√©diction dans l'historique"""
        history_entry = {
            'timestamp': datetime.now().isoformat(),
            'input': {
                'code_dtc': code_dtc,
                'description': description,
                'root_cause': root_cause
            },
            'prediction': result['predicted_pca'],
            'confidence': result.get('confidence', 0)
        }
        
        st.session_state.prediction_history.append(history_entry)
        
        # Limiter l'historique √† 50 entr√©es
        if len(st.session_state.prediction_history) > 50:
            st.session_state.prediction_history = st.session_state.prediction_history[-50:]
    
    def render_history(self):
        """Affiche l'historique des pr√©dictions"""
        if not st.session_state.prediction_history:
            st.info("üìù Aucune pr√©diction dans l'historique")
            return
        
        st.header("üìà Historique des Pr√©dictions")
        
        # Conversion en DataFrame pour l'affichage
        history_data = []
        for entry in reversed(st.session_state.prediction_history[-10:]):  # 10 derni√®res
            history_data.append({
                'Horodatage': datetime.fromisoformat(entry['timestamp']).strftime("%d/%m/%Y %H:%M"),
                'Code DTC': entry['input']['code_dtc'],
                'Description': entry['input']['description'][:50] + '...' if len(entry['input']['description']) > 50 else entry['input']['description'],
                'PCA Pr√©dite': entry['prediction'][:50] + '...' if len(entry['prediction']) > 50 else entry['prediction'],
                'Confiance': f"{entry['confidence']:.1%}"
            })
        
        df_history = pd.DataFrame(history_data)
        st.dataframe(df_history, use_container_width=True)
        
        # Graphique de l'√©volution de la confiance
        if len(st.session_state.prediction_history) > 1:
            confidences = [entry['confidence'] for entry in st.session_state.prediction_history[-20:]]
            timestamps = [datetime.fromisoformat(entry['timestamp']) for entry in st.session_state.prediction_history[-20:]]
            
            fig = go.Figure()
            fig.add_trace(go.Scatter(
                x=timestamps,
                y=confidences,
                mode='lines+markers',
                name='Confiance',
                line=dict(color='#1f77b4', width=2)
            ))
            fig.update_layout(
                title="√âvolution de la Confiance des Pr√©dictions",
                xaxis_title="Temps",
                yaxis_title="Confiance",
                height=300
            )
            st.plotly_chart(fig, use_container_width=True)
    
    def get_confidence_level(self, confidence: float) -> str:
        """D√©termine le niveau de confiance"""
        if confidence >= 0.8:
            return "Tr√®s √©lev√©e"
        elif confidence >= 0.6:
            return "√âlev√©e"
        elif confidence >= 0.4:
            return "Moyenne"
        elif confidence >= 0.2:
            return "Faible"
        else:
            return "Tr√®s faible"
    
    def render_gim_chat_tab(self):
        """Affiche l'onglet du chatbot GIM"""
        st.header("ü§ñ Assistant GIM - Global Issue Management")

        # Gestion des questions rapides depuis la sidebar
        if st.session_state.quick_gim_question:
            st.info(f"üí¨ Question rapide : {st.session_state.quick_gim_question}")

            # Traiter la question automatiquement
            if 'gim_chat_history' not in st.session_state:
                st.session_state.gim_chat_history = []

            # Obtenir la r√©ponse
            if self.gim_chatbot.is_available:
                response = self.gim_chatbot.get_response(st.session_state.quick_gim_question)
            else:
                response = demo_mode_response(st.session_state.quick_gim_question)

            # Ajouter √† l'historique
            exchange = {
                "user": st.session_state.quick_gim_question,
                "bot": response,
                "timestamp": datetime.now().strftime("%d/%m/%Y %H:%M:%S")
            }
            st.session_state.gim_chat_history.append(exchange)

            # R√©initialiser la question rapide
            st.session_state.quick_gim_question = None

        # Interface de chat compl√®te
        self.gim_chatbot.render_chat_interface()

    def run(self):
        """Lance l'application Streamlit"""
        self.render_header()
        self.render_sidebar()

        # Gestion de l'affichage du chat GIM
        if st.session_state.show_gim_chat:
            # Onglets avec GIM visible
            tab1, tab2, tab3 = st.tabs(["üéØ Pr√©diction PCA", "ü§ñ Assistant GIM", "üìà Historique"])

            with tab1:
                self.render_prediction_form()

            with tab2:
                self.render_gim_chat_tab()

            with tab3:
                self.render_history()
        else:
            # Onglets normaux
            tab1, tab2 = st.tabs(["üéØ Pr√©diction PCA", "üìà Historique"])

            with tab1:
                self.render_prediction_form()

                # Bouton pour ouvrir le chat GIM
                st.markdown("---")
                col1, col2, col3 = st.columns([1, 2, 1])
                with col2:
                    if st.button("ü§ñ Ouvrir l'Assistant GIM", use_container_width=True, type="secondary"):
                        st.session_state.show_gim_chat = True
                        st.rerun()

            with tab2:
                self.render_history()


def main():
    """Fonction principale de l'application Streamlit"""
    app = PCAStreamlitApp()
    app.run()


if __name__ == "__main__":
    main()
